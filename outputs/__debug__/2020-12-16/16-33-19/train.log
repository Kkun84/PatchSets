[2020-12-16 16:33:19,505][__main__][INFO] - 
project_name: PatchSets
experiment_name: __debug__
debug: true
hparams:
  patch_size: 15
  hidden_n: 64
  feature_n: 2
  output_n: ${data.class_num}
  pool_mode: sum
  patch_num_min: 1
  patch_num_max: 256
  seed: 0
  batch_size: 256
  num_workers: 6
  max_epochs: 10000
  min_epochs: 10
  patience: 50
  optimizer: Adam
  lr: 0
  data_split_num: ${data.datamodule.data_split_num}
  data_use_num: ${data.datamodule.data_use_num}
data:
  datamodule:
    _target_: src.datamodule.AdobeFontDataModule
    path: /dataset/AdobeFontCharImages
    upper: true
    lower: false
    data_split_num: 5
    data_use_num: 0
    seed: ${hparams.seed}
    batch_size: ${hparams.batch_size}
    num_workers: ${hparams.num_workers}
  name: AdobeFontCharImages
  class_num: 26
trainer:
  max_epochs: ${hparams.max_epochs}
  min_epochs: ${hparams.min_epochs}
  auto_scale_batch_size: false
  gpus: 1
  auto_select_gpus: true
  num_nodes: 1
  accelerator: null
  benchmark: true
  deterministic: true
  gradient_clip_val: 0
  track_grad_norm: -1
  overfit_batches: 0.0
  precision: 32
  fast_dev_run: ${debug}
  profiler: simple
  weights_summary: full
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
model_checkpoint:
  monitor: valid_loss
  verbose: false
  save_last: null
  save_top_k: null
  save_weights_only: false
  mode: min
  prefix: ''
  dirpath: ./checkpoints
  filename: null
early_stopping:
  monitor: valid_loss
  min_delta: 0
  patience: ${hparams.patience}
  verbose: false
  mode: min
callbacks: []
loggers: []

[2020-12-16 16:33:21,022][lightning][INFO] - GPU available: True, used: True
[2020-12-16 16:33:21,022][lightning][INFO] - TPU available: False, using: 0 TPU cores
[2020-12-16 16:33:21,023][lightning][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[2020-12-16 16:33:21,023][lightning][INFO] - Running in fast_dev_run mode: will run a full train, val and test loop using a single batch
[2020-12-16 16:33:32,836][lightning][INFO] - 
  | Name             | Type     | Params
----------------------------------------------
0 | accuracy         | Accuracy | 0     
1 | flatten          | Flatten  | 0     
2 | encoder_linear_1 | Linear   | 14 K  
3 | encoder_linear_2 | Linear   | 130   
4 | decoder_linear_1 | Linear   | 192   
5 | decoder_linear_2 | Linear   | 1 K   
[2020-12-16 16:33:35,827][lightning][INFO] - 

Profiler Report

Action              	|  Mean duration (s)	|  Total time (s) 
-----------------------------------------------------------------
on_fit_start        	|  5.7408e-05     	|  5.7408e-05     
on_train_start      	|  4.6988e-05     	|  4.6988e-05     
on_epoch_start      	|  4.3091e-05     	|  4.3091e-05     
on_train_epoch_start	|  4.0686e-05     	|  4.0686e-05     
get_train_batch     	|  0.42684        	|  0.42684        
on_batch_start      	|  0.002838       	|  0.002838       
on_train_batch_start	|  0.0001209      	|  0.0001209      
training_step_end   	|  3.8261e-05     	|  3.8261e-05     
model_forward       	|  0.33196        	|  0.33196        
model_backward      	|  0.039331       	|  0.039331       
on_after_backward   	|  1.8214e-05     	|  1.8214e-05     
optimizer_step      	|  0.3735         	|  0.3735         
on_batch_end        	|  5.5724e-05     	|  5.5724e-05     
on_train_batch_end  	|  0.00059074     	|  0.00059074     
on_validation_start 	|  4.9393e-05     	|  4.9393e-05     
on_validation_epoch_start	|  4.3502e-05     	|  4.3502e-05     
on_validation_batch_start	|  0.00017037     	|  0.00017037     
validation_step_end 	|  4.5976e-05     	|  4.5976e-05     
on_validation_batch_end	|  5.5103e-05     	|  5.5103e-05     
on_validation_epoch_end	|  0.00010165     	|  0.00010165     
on_validation_end   	|  0.00010326     	|  0.00010326     
on_epoch_end        	|  8.4307e-05     	|  8.4307e-05     
on_train_epoch_end  	|  0.000112       	|  0.000112       
on_train_end        	|  0.00012043     	|  0.00012043     

[2020-12-16 16:33:35,832][lightning][INFO] - LR finder stopped early due to diverging loss.
[2020-12-16 16:33:35,837][lightning][ERROR] - Failed to compute suggesting for `lr`. There might not be enough points.
Traceback (most recent call last):
  File "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/tuner/lr_finder.py", line 344, in suggestion
    min_grad = np.gradient(loss).argmin()
  File "<__array_function__ internals>", line 6, in gradient
  File "/opt/conda/lib/python3.7/site-packages/numpy/lib/function_base.py", line 1042, in gradient
    "Shape of array too small to calculate a numerical gradient, "
ValueError: Shape of array too small to calculate a numerical gradient, at least (edge_order + 1) elements are required.
[2020-12-16 16:33:35,838][lightning][INFO] - Learning rate set to None
[2020-12-16 16:33:35,848][lightning][INFO] - 
  | Name             | Type     | Params
----------------------------------------------
0 | accuracy         | Accuracy | 0     
1 | flatten          | Flatten  | 0     
2 | encoder_linear_1 | Linear   | 14 K  
3 | encoder_linear_2 | Linear   | 130   
4 | decoder_linear_1 | Linear   | 192   
5 | decoder_linear_2 | Linear   | 1 K   
[2020-12-16 16:33:47,415][__main__][INFO] - All done.
